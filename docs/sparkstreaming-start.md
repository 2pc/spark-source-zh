### SparkStreaming序

前面已经基本分析完了Spark Core的核心代码，用它来做离线计算已经完全够用了，但是咱的目的并不是这个啊，咱要学的是实时流式处理，嗯，这就是接下来一段
时间要分析的一个分支--Spark Streaming，它依赖于Spark Core作为基础架构，因此Spark Streaming会因为Spark Core本身的一些架构上的原因而有一些
天然的限制。比如说，Spark Streaming采用的是一种微批的处理方式，也就是它会将非常小的一段时间内的数据攒在一起形成一个微批，然后定时的去触发计算。
我们知道在Flink中有窗口的概念，一个窗口内的数据会在窗口结束时触发计算(或者用定时器也能触发)。那么同样都是攒批延迟计算，它们的区别在哪里呢？我觉得
从结果来看它们并没有多少区别，它们之间最大的区别就在于：Flink窗口的延迟计算是由业务导致的，也就是说业务上需要对乱序的数据进行处理，所以有了窗口；
而Spark Streaming的延迟计算是它本身的架构导致的，由于它依赖于Spark Core的架构，所以它只能用攒批的方式来实现准实时的流式计算。

架构上的缺陷注定了Spark Streaming更像是一种临时的解决方案，但是为何这种看上去很临时的解决方案却被广泛使用呢？因为Spark streaming架构在Spark之上，
而Spark出现的时间是比较早的，因此从Spark到Spark Streaming开发人员和企业都比较接受，运维也可以由同一拨人来完成，节省成本。这也说明了有时候对于市场
来说，并不一定是技术最好的产品最吃香，市场的选择考虑的东西非常之多。