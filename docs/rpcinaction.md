### 深入Spark RPC

在Spark源码解析中曾经分析到Spark新版采用的是Netty来进行节点间的通信，当然Netty也是Storm、Flink节点间通信的主要方式，在Netty4中能提供全双工、多路
复用I/O模型的Socket I/O能力，既然实时计算引擎都使用Netty来进行节点间的通信，那么可以肯定Netty的通信效率一定是特别高的，不然也不能满足实时计算这种
对传输效率要求非常高的场合。恰好，最近做个性化实时推送，每天大概要推送7亿条左右的数据，需要解决机器节点间的高效率通信问题。于是，打算借鉴一下Spark的底
层通信方式来实现。

既然打算借鉴，那首先就必须对Spark节点间的RPC有一个深入的了解才行，于是在前面已经阅读过相关源码的基础上，咱们再有目的的深入分析研究一下，以方便咱的这个
借鉴过程^-^！

