### 深入Spark RPC

在Spark源码解析中曾经分析到Spark新版采用的是Netty来进行节点间的通信，当然Netty也是Storm、Flink节点间通信的主要方式，在Netty4中能提供全双工、多路
复用I/O模型的Socket I/O能力，既然实时计算引擎都使用Netty来进行节点间的通信，那么可以肯定Netty的通信效率一定是特别高的，不然也不能满足实时计算这种
对传输效率要求非常高的场合。恰好，最近做个性化实时推送，每天大概要推送7亿条左右的数据，需要解决机器节点间的高效率通信问题。于是，打算借鉴一下Spark的底
层通信方式来实现。

既然打算借鉴，那首先就必须对Spark节点间的RPC有一个深入的了解才行，于是在前面已经阅读过相关源码的基础上，咱们再有目的的深入分析研究一下，以方便咱的这个
借鉴过程^-^！

先回顾一下[Spark源码阅读5：RpcEnv](./master/docs/rpcenv.md)的知识。首先，RPC环境承担着Spark体系内几乎所有的内部及外部通信，RpcEnv抽象类是Spark
RPC环境的通用表示，其需要由SparkConf组件加载Spark中RPC相关的配置，但RpcEnv知识一个抽象类，NettyRpcEnv是Spark官方提供的RPC环境的唯一实现，通过
NettyRpcEnvFactory的create()方法创建，这个方法先创建JavaSerializer序列化器，用于RPC传输的序列化，然后通过NettyRpcEnv的构造方法创建NettyRpcEnv，
这其中也包含一些RPC基础组件的初始化，最后定义函数变量startNettyRpcEnv并调用工具类Utils中的startServiceOnPort()方法来启动NettyRpcEnv。如此就能得到
Spark RPC环境了。之后再在这层环境上使用RpcEndpoint进行通信就是顺利成章的事了。

好了，到了这里，相信大家应该已经明确了我们的借鉴过程的起点应该是SparkConf，不过SparkConf负责管理的是整个Spark的配置项，我们需要借鉴的只是RPC相关的东西，
并不需要那么多，其实可以给它进行一下瘦身工作。关于SparkConf的知识，可以参考[Spark源码阅读1：SparkConf](./master/docs/sparkconf.md)。

在完成了SparkConf的瘦身后，就来到了RpcEnv这个抽象类，在这个类中RpcEnvFileServer类没什么作用，完全可以去掉，另外为了让它能正常运行还得添加一些额外的
工具类。在这个类中，我们知道最重要的方法是在其中定义的setupEndpoint()方法，它用来注册一个RPC端点(RpcEndpoint)，并返回其引用(RpcEndpointRef)。如果
客户端想向一个RpcEndpoint发送消息，那么首先必须就获取其对应RpcEndpoint的引用。

再来看一下RpcEnv抽象类的唯一实现NettyRpcEnv类，首先要创建它必须要通过NettyRpcEnvFactory类的create()方法，它接收一个参数RpcEnvConfig。这个配置类
与RpcEnv在同一个文件中，是一个简单的样例类，对SparkConf进行了简单的封装，增加了一些RPC通信额外必需的参数，包括IP、端口号等等。在create()方法中会先创建
Java序列化器，然后构造NettyRpcEnv实例。